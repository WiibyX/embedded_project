{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "attractive-intake",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from PIL import Image\n",
    "import xml.etree.ElementTree as ET\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "import keras.optimizers\n",
    "import random\n",
    "import scipy\n",
    "import math\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sensitive-albert",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgFileDir = r'C:\\Users\\WillyB\\Documents\\GitHub\\embedded_project\\Stanford40_JPEGImages\\JPEGImages'\n",
    "CImagesDir = r'C:\\Users\\WillyB\\Documents\\GitHub\\embedded_project\\Stanford40_JPEGImages\\CImages'\n",
    "parentImgFileDir = r'C:\\Users\\WillyB\\Documents\\GitHub\\embedded_project\\Stanford40_JPEGImages'\n",
    "xmlFileDir = r'C:\\Users\\WillyB\\Documents\\GitHub\\embedded_project\\Stanford40_XMLAnnotations\\XMLAnnotations'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ruled-indonesian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractClassLabels(xmlFileDir):\n",
    "    os.chdir(xmlFileDir)\n",
    "    xmlFileNames = [f for f in listdir(xmlFileDir) if isfile(join(xmlFileDir, f))]\n",
    "    #xmlFileNames = ['3m1.xml','3m2.xml','3m3.xml','3m4.xml']\n",
    "    classLabels = []\n",
    "    imageNames = []\n",
    "    for file in xmlFileNames:\n",
    "        root = ET.parse(file).getroot()\n",
    "        filename = root.find('filename').text\n",
    "        action = root.find('object/action').text\n",
    "        classLabels.append(action)\n",
    "        imageNames.append(filename)\n",
    "    return np.array(classLabels), np.array(imageNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "necessary-stephen",
   "metadata": {},
   "outputs": [],
   "source": [
    "classList, allImageNames = extractClassLabels(xmlFileDir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "conceptual-tiger",
   "metadata": {},
   "outputs": [],
   "source": [
    "(classUnique,counts) = np.unique(classList, return_counts=True)\n",
    "\n",
    "(_,inverse) = np.unique(classList, return_inverse=True)\n",
    "\n",
    "y = to_categorical(inverse,len(classUnique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "second-recovery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9532 files belonging to 40 classes.\n",
      "Using 7626 files for training.\n",
      "Found 9532 files belonging to 40 classes.\n",
      "Using 1906 files for validation.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "img_height = 90\n",
    "img_width = 90\n",
    "actionImagesDir = r'C:\\Users\\WillyB\\Documents\\GitHub\\embedded_project\\Stanford40_JPEGImages\\ActionImages'\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    actionImagesDir,\n",
    "    validation_split=0.2,\n",
    "    label_mode = 'categorical',\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    actionImagesDir,\n",
    "    validation_split=0.2,\n",
    "    label_mode = 'categorical',\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "returning-patrol",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x00000216FA83D3A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x00000216FA83D3A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\n",
    "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "critical-heating",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "#train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "double-family",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_47 (Conv2D)           (None, 88, 88, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 44, 44, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 44, 44, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 42, 42, 64)        18496     \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 42, 42, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_49 (Conv2D)           (None, 40, 40, 128)       73856     \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 40, 40, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 20, 20, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 51200)             0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 512)               26214912  \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 40)                5160      \n",
      "=================================================================\n",
      "Total params: 26,477,544\n",
      "Trainable params: 26,477,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def define_model(nrOfClasses):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(90 ,90, 3)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.20))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dropout(0.20))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dropout(0.20))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(256, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(nrOfClasses, activation='softmax'))\n",
    "    # compile modelÂ¨\n",
    "    opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "    #opt = SGD(lr=0.001, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "model = define_model(len(classUnique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "therapeutic-entrepreneur",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: ((None, 90, 90, 3), (None, 40)), types: (tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "broke-difficulty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None, 90, 90, 3), (None, 40)), types: (tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "white-credits",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021583C785E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021583C785E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "239/239 [==============================] - 13s 56ms/step - loss: 4.3934 - accuracy: 0.0273\n",
      "Epoch 2/2\n",
      "239/239 [==============================] - 13s 55ms/step - loss: 3.6738 - accuracy: 0.0309\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x216fa7db188>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, epochs = 2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dietary-hollywood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000216F5D33F78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000216F5D33F78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "60/60 [==============================] - 9s 157ms/step - loss: 72.2866 - accuracy: 0.0362\n",
      "[72.28661346435547, 0.03620146960020065]\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(test_ds, batch_size=32, verbose =1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "backed-purse",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gputest",
   "language": "python",
   "name": "gputest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
