{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informed-shannon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from PIL import Image\n",
    "import xml.etree.ElementTree as ET\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "import keras.optimizers\n",
    "import random\n",
    "import scipy\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dense-conditioning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE THIS to the path on your machine\n",
    "projectDir = r'C:\\Users\\Viktor\\Skola\\embedded\\embedded_project'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smaller-broadcasting",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgFileDir = os.path.join(projectDir,'Stanford40_JPEGImages\\JPEGImages')\n",
    "CImagesDir = os.path.join(projectDir,'Stanford40_JPEGImages\\CImages')\n",
    "parentImgFileDir = os.path.join(projectDir,'Stanford40_JPEGImages')\n",
    "xmlFileDir = os.path.join(projectDir,'Stanford40_XMLAnnotations\\XMLAnnotations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functional-jenny",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractClassLabels(xmlFileDir):\n",
    "    os.chdir(xmlFileDir)\n",
    "    xmlFileNames = [f for f in listdir(xmlFileDir) if isfile(join(xmlFileDir, f))]\n",
    "    #xmlFileNames = ['3m1.xml','3m2.xml','3m3.xml','3m4.xml']\n",
    "    classLabels = []\n",
    "    imageNames = []\n",
    "    count = 1\n",
    "    for file in xmlFileNames:\n",
    "        root = ET.parse(file).getroot()\n",
    "        filename = root.find('filename').text\n",
    "        action = root.find('object/action').text\n",
    "        classLabels.append(action)\n",
    "        imageNames.append(filename)\n",
    "        print(str(count)+'/'+str(len(xmlFileNames)), end='\\r')\n",
    "        count +=1\n",
    "    return np.array(classLabels), np.array(imageNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thirty-trust",
   "metadata": {},
   "outputs": [],
   "source": [
    "classList, allImageNames = extractClassLabels(xmlFileDir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proprietary-spice",
   "metadata": {},
   "outputs": [],
   "source": [
    "(classUnique,counts) = np.unique(classList, return_counts=True)\n",
    "\n",
    "(_,inverse) = np.unique(classList, return_inverse=True)\n",
    "\n",
    "y = to_categorical(inverse,len(classUnique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removed-assignment",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 90\n",
    "img_width = 90\n",
    "actionImagesDir = os.path.join(projectDir,'Stanford40_JPEGImages\\ActionImages')\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    actionImagesDir,\n",
    "    validation_split=0.2,\n",
    "    label_mode = 'categorical',\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    actionImagesDir,\n",
    "    validation_split=0.2,\n",
    "    label_mode = 'categorical',\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "looking-carol",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\n",
    "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absolute-scientist",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "#train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "built-birmingham",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_model(nrOfClasses):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(90 ,90, 3)))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(256, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(nrOfClasses, activation='softmax'))\n",
    "    opt = keras.optimizers.Adam(0.0001)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "tuned_model = best_model(len(classUnique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "published-actress",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(nrOfClasses, hyperparameters):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(hyperparameters[\"nrOfFiltersInConvLayers\"][0], (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(90 ,90, 3)))\n",
    "    \n",
    "    for nrOfFilters in hyperparameters[\"nrOfFiltersInConvLayers\"][1:]:\n",
    "        model.add(Conv2D(nrOfFilters, (3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
    "        model.add(MaxPooling2D((2, 2)))\n",
    "        model.add(Dropout(hyperparameters[\"dropout\"]))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    for nrOfNeurons in hyperparameters[\"nrOfNeuronsInHiddenLayers\"]:\n",
    "        model.add(Dense(nrOfNeurons, activation='relu', kernel_initializer='he_uniform'))\n",
    "        \n",
    "    model.add(Dense(nrOfClasses, activation='softmax'))\n",
    "    # compile modelÂ¨\n",
    "    opt = keras.optimizers.Adam(learning_rate=hyperparameters[\"learningRate\"])\n",
    "    #opt = SGD(lr=0.001, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    #model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lyric-springfield",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nrOfConvLayers = [2,3,4]\n",
    "nrOfFilters = [16,32,64,128]\n",
    "nrOfHiddenLayers = [2,3,4]\n",
    "nrOfHiddenLayerNeurons = [32,64,128,256,512]\n",
    "dropout = [0.2,0.5,0.8]\n",
    "learningRate = [0.00001,0.0001,0.001]\n",
    "\n",
    "tests = 100\n",
    "\n",
    "bestAccuracy = 0\n",
    "bestHyperparameters = None\n",
    "\n",
    "for test in range(tests):\n",
    "    hyperparameters = {\n",
    "        'nrOfFiltersInConvLayers': [],\n",
    "        'nrOfNeuronsInHiddenLayers':[],\n",
    "        'dropout': random.choice(dropout),\n",
    "        'learningRate':random.choice(learningRate)\n",
    "    }\n",
    "    \n",
    "    for layer in range(random.choice(nrOfConvLayers)):\n",
    "        hyperparameters['nrOfFiltersInConvLayers'].append(random.choice(nrOfFilters))\n",
    "    \n",
    "    \n",
    "    for layer in range(random.choice(nrOfHiddenLayers)):\n",
    "        hyperparameters['nrOfNeuronsInHiddenLayers'].append(random.choice(nrOfHiddenLayerNeurons))\n",
    "                       \n",
    "    print(hyperparameters)\n",
    "    \n",
    "    model = define_model(len(classUnique),hyperparameters)\n",
    "    model.fit(train_ds, epochs=20)\n",
    "    result = model.evaluate(test_ds, batch_size=32)\n",
    "    accuracy = result[1]\n",
    "    \n",
    "    if accuracy > bestAccuracy:\n",
    "        bestAccuracy = accuracy\n",
    "        bestHyperparameters = hyperparameters\n",
    "    \n",
    "    print(bestAccuracy)\n",
    "    print(bestHyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consistent-canadian",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_model.fit(train_ds, epochs=20)\n",
    "result = tuned_model.evaluate(test_ds, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "younger-ministry",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "practical-stanley",
   "metadata": {},
   "outputs": [],
   "source": [
    "parentModelDir = os.path.join(projectDir,'code')\n",
    "os.chdir(parentModelDir)\n",
    "savedModelDir = os.path.join(parentModelDir, \"saved_model\")\n",
    "if os.path.exists(savedModelDir):\n",
    "    print(\"it exist\")\n",
    "else:\n",
    "    print(\"does not exist, create folder\")\n",
    "    os.mkdir(savedModelDir)\n",
    "\n",
    "tuned_model.save('saved_model/my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polar-still",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to tensorflow lite model\n",
    "# Convert the model\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(savedModelDir+'/my_model') # path to the SavedModel directory\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "os.makedirs(os.path.join(os.getcwd(),'saved_tflite_models'), exist_ok = True)\n",
    "# Save the model.\n",
    "with open('./saved_tflite_models/model_1.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solid-employment",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load tensorflow lite model\n",
    "interpreter = tf.lite.Interpreter(model_path='./saved_tflite_models/model_1.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noted-planning",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hourly-landscape",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_batches = tfds.as_numpy(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-priority",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_images = 0\n",
    "for batch in ds_batches:\n",
    "    for image in batch[1]:\n",
    "        count_images +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "white-hebrew",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relevant-warner",
   "metadata": {},
   "outputs": [],
   "source": [
    "xTest = np.zeros((count_images, 90,90,3)).astype('float32')\n",
    "yTest = np.zeros((count_images,40)).astype('float32')\n",
    "\n",
    "batch_number = 0\n",
    "for batch in ds_batches:\n",
    "    for image_number in range(len(batch[0])):\n",
    "        xTest[batch_number*32+image_number] = batch[0][image_number]\n",
    "        yTest[batch_number*32+image_number] = batch[1][image_number]\n",
    "    batch_number +=1\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quantitative-factor",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_predict = 0\n",
    "for image_number in range(len(xTest)): \n",
    "    interpreter.set_tensor(input_details[0]['index'], xTest[image_number][np.newaxis, ...])\n",
    "    interpreter.invoke()\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    if (output_data[0] == yTest[image_number]).all():\n",
    "        correct_predict +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marked-oliver",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = correct_predict/count_images\n",
    "accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
